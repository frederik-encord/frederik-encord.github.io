---
title: "Are Visual Foundation Models (VFMs) on par with SOTA?"
date: "2023-05-03T00:00:00+02:00"
draft: false
tags:
  - webinar
  - sam
  - grounding-dino
  - vfm
  - object detection
  - instance segmentation
cover:
  image: "https://img.youtube.com/vi/SU9Vlv5NlzQ/0.jpg"
  alt: "Are Visual Foundation Models (VFMs) on par with SOTA?"
  relative: false
---

{{< youtube id=SU9Vlv5NlzQ >}}

With Foundational Models increasing in prominence, Encord's President and Co-Founder will sit down with our Lead ML Engineer to dissect Meta's new Visual Foundation Model, Segment Anything Model (SAM). After combining the model with Grounding-DINO to allow for zero-shot segmentation, the team will compare it to a SOTA Mask-RCNN model to see whether the development of SAM really is revolutionary for segmentation. We discussed:

- The rise of VFMs and how they differ from standard models
- What Meta's release of DINOv2 means for Grounding-DINO + SAM
- How SAM and Grounding-DINO compare to previous segmentation models for performance and predictions
- Evaluating model performance using Encord Active
